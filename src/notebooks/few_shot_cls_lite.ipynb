{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d5ceee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jinjiewu/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "\n",
    "import time\n",
    "import random\n",
    "from queue import Queue\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, recall_score, confusion_matrix\n",
    "\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "pd.set_option('display.max_rows', None) # Force to display all rows of tables\n",
    "#pd.set_option('display.max_rows', 20)\n",
    "\n",
    "from gemini_api import GeminiAPIHandler\n",
    "from cls_eval import cal_specificity, save_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02304659",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_total = 500\n",
    "\n",
    "# Dataset paths\n",
    "dataset = \"derm12345\"\n",
    "dataset_path = f\"../../datasets/{dataset}\"\n",
    "\n",
    "cls_criteria = \"melanocytic_binary\"\n",
    "#cls_criteria = \"melanocytic_malignancy\"\n",
    "if cls_criteria == \"melanocytic_binary\":\n",
    "    class_labels = [\"melanocytic\", \"nonmelanocytic\"]\n",
    "elif cls_criteria == \"melanocytic_malignancy\":\n",
    "    class_labels = [\"melanocytic benign\",\n",
    "                    \"melanocytic malignant\",\n",
    "                    \"nonmelanocytic benign\",\n",
    "                    \"nonmelanocytic indeterminate\",\n",
    "                    \"nonmelanocytic malignant\"]\n",
    "\n",
    "metadata_path = os.path.join(dataset_path, \"metadata.csv\")\n",
    "metadata = pd.read_csv(metadata_path)\n",
    "\n",
    "output_dir = f\"../api_cls/{dataset}_{cls_criteria}\"\n",
    "os.makedirs(os.path.dirname(output_dir), exist_ok=True)\n",
    "\n",
    "log_filename = os.path.join(output_dir, \"api_clscont.log\")\n",
    "os.makedirs(os.path.dirname(log_filename), exist_ok=True)\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, \n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', \n",
    "    filename=log_filename\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24eebe38",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(dotenv_path=\"../../.env\")\n",
    "\n",
    "api_key_indices = [2, 3, 4]\n",
    "#api_key_indices = [1, 2, 3]\n",
    "api_handler_queue = Queue()\n",
    "\n",
    "model_name = \"gemini-2.0-flash-exp\"\n",
    "request_interval = 3\n",
    "#model_name = \"gemini-2.0-flash-thinking-exp\"\n",
    "#request_interval = 12\n",
    "\n",
    "for index in api_key_indices:\n",
    "    api_key = os.getenv(f\"GEMINI_API_KEY_{index}\")\n",
    "    api_handler = GeminiAPIHandler(\n",
    "        api_key=api_key, \n",
    "        index=index, \n",
    "        model_name=model_name, \n",
    "        request_interval=request_interval, \n",
    "        logger=logger\n",
    "    )\n",
    "    api_handler_queue.put(api_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8410b1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def toggle_api_handler(old_handler, api_handler_queue, toggle_reason):\n",
    "    api_handler_queue.put(old_handler) # Requeue the old API handler\n",
    "    new_handler = api_handler_queue.get()\n",
    "    logger.info(f\"{toggle_reason}. Switch to API_Handler_{new_handler.index}\")\n",
    "    return new_handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83babc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_queue = Queue()\n",
    "\n",
    "# Filter the images with non-empty label\n",
    "metadata = metadata[metadata['label'].replace(r'^\\s*$', pd.NA, regex=True).notna()]\n",
    "\n",
    "img_ids = [id for id in metadata['image_id'].dropna().unique()]\n",
    "random.shuffle(img_ids) # Shuffle the image IDs for even class distribution\n",
    "\n",
    "for img_id in img_ids[:img_total]: img_queue.put(img_id)\n",
    "results = pd.DataFrame()\n",
    "\n",
    "# Parse all existing response files in the output directory\n",
    "existing_response_files = [f for f in os.listdir(output_dir) if f.endswith('.json')]\n",
    "for filename in existing_response_files:\n",
    "    file_path = os.path.join(output_dir, filename)\n",
    "    with open(file_path, 'r') as f:\n",
    "        stored_result = json.load(f)\n",
    "    stored_result_df = pd.DataFrame([stored_result])\n",
    "    results = pd.concat([results, stored_result_df], ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fadccee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a dermatologist examining a skin lesion image.\n",
      "Classify the lesion into exactly one of the following classes:\n",
      "    • melanocytic\n",
      "    • nonmelanocytic\n",
      "Rules:\n",
      "1. Output only the class name.\n",
      "2. Do not include any extra text, punctuation, or explanation.\n"
     ]
    }
   ],
   "source": [
    "prompt = (\n",
    "    \"You are a dermatologist examining a skin lesion image.\\n\"\n",
    "    \"Classify the lesion into exactly one of the following classes:\\n\"\n",
    "    \"{class_labels_str}\\n\"\n",
    "    \"Rules:\\n\"\n",
    "    \"1. Output only the class name.\\n\"\n",
    "    \"2. Do not include any extra text, punctuation, or explanation.\"\n",
    ").format(class_labels_str='\\n'.join(f\"    • {label}\" for label in class_labels))\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674780a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_gemini_api_cls_lite(image_id:str):\n",
    "    image_path = os.path.join(dataset_path, image_id + '.jpg')\n",
    "    metadata_row = metadata[metadata['image_id'] == image_id].iloc[0]\n",
    "\n",
    "    with Image.open(image_path) as pil_image:\n",
    "        answer = api_handler.generate_from_pil_image(pil_image, prompt=prompt).rstrip('\\n').lower()\n",
    "    if answer not in {\"melanocytic\", \"nonmelanocytic\"}:\n",
    "        answer = \"malformed output\"\n",
    "\n",
    "    if cls_criteria == \"melanocytic_binary\":\n",
    "        truth = str(metadata_row['super_class'])\n",
    "    elif cls_criteria == \"melanocytic_malignancy\":\n",
    "        truth = str(metadata_row['super_class']) + ' ' + str(metadata_row['malignancy'])\n",
    "\n",
    "    return {\n",
    "        \"image_id\": image_id,\n",
    "        \"answer\": answer,\n",
    "        \"truth\": truth\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec418679",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_cls_lite(results:pd.DataFrame, cls_criteria:str, labels:list, isprocessing:bool=False):\n",
    "    accuracy = accuracy_score(results['truth'], results['answer'])\n",
    "    cm = confusion_matrix(results['truth'], results['answer'], labels=labels)\n",
    "    sensitivity = recall_score(results['truth'], results['answer'], average=\"macro\", labels=labels, zero_division=0)\n",
    "    specificity = cal_specificity(labels, cm, average=\"macro\")\n",
    "    message = f\"Accuracy={accuracy:.3%}, Sensitivity={sensitivity:.3%}, Specificity={specificity:.3%}\"\n",
    "\n",
    "    if isprocessing:\n",
    "        tqdm.write(message)\n",
    "    else:\n",
    "        print(message)\n",
    "\n",
    "        eval_dir = os.path.join(output_dir, \"evaluation_metrics\")\n",
    "        os.makedirs(os.path.dirname(eval_dir), exist_ok=True)\n",
    "\n",
    "        cm_df = pd.DataFrame(cm, index=labels, columns=labels)\n",
    "        save_eval(cm_df, eval_dir, \"confusion_matrix\", format='xlsx', index=True)\n",
    "\n",
    "        malformed_rate = results['answer'].value_counts().get(\"malformed output\", 0) / len(results)\n",
    "        eval_metrics = {\n",
    "            'Accuracy': f\"{accuracy:.3%}\",\n",
    "            'Sensitivity (Macro)': f\"{sensitivity:.3%}\",\n",
    "            'Specificity (Macro)': f\"{specificity:.3%}\",\n",
    "            'Malformed Rate': f\"{malformed_rate:.3%}\",\n",
    "        }\n",
    "        save_eval(pd.DataFrame([eval_metrics]), eval_dir, \"overall_evaluation\", format='xlsx', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a573573e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tqdm progress bar\n",
    "progress_bar = tqdm(total=img_total, desc=\"Processing images\", unit=\"img\")\n",
    "progress_bar.n = len(existing_response_files)\n",
    "progress_bar.refresh()\n",
    "\n",
    "# Monitor the progress\n",
    "now = time.time()\n",
    "latest_update = now\n",
    "\n",
    "api_handler = api_handler_queue.get()\n",
    "handler_task_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc84bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "while progress_bar.n < img_total:\n",
    "    image_id = img_queue.get()\n",
    "    task_exists = False\n",
    "    progress_made = False\n",
    "\n",
    "    try:\n",
    "        generated_response_file = os.path.join(output_dir, f\"{image_id}_cls.json\")\n",
    "        \n",
    "        if os.path.exists(generated_response_file):\n",
    "            logger.info(f\"Skipping image_id {image_id} as response already exists.\")\n",
    "            task_exists = True\n",
    "\n",
    "        else:\n",
    "            result = call_gemini_api_cls_lite(image_id)\n",
    "            result_df = pd.DataFrame([result])\n",
    "            results = pd.concat([results, result_df], ignore_index=True)\n",
    "\n",
    "            with open(generated_response_file, 'w') as out_file:\n",
    "                json.dump(result, out_file, indent=4)\n",
    "            logger.info(f\"Successfully processed image_id {image_id}, saved to {generated_response_file}\")\n",
    "            progress_made = True\n",
    "            handler_task_count += 1\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Error processing image_id {image_id}: {e}\")\n",
    "        \n",
    "        # Requeue the request\n",
    "        img_queue.put(image_id)\n",
    "\n",
    "    finally:\n",
    "        img_queue.task_done()\n",
    "\n",
    "        now = time.time()\n",
    "        if (now - latest_update > 180):\n",
    "            api_handler = toggle_api_handler(api_handler, api_handler_queue, \"API request timeout\")\n",
    "            handler_task_count = 0\n",
    "\n",
    "        if not task_exists and progress_made:    \n",
    "            progress_bar.update(1)\n",
    "            if progress_bar.n % 50 == 0:\n",
    "                eval_cls_lite(results, cls_criteria, class_labels, isprocessing=True)\n",
    "            latest_update = now\n",
    "\n",
    "progress_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5126c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dir = os.path.join(output_dir, \"evaluation_metrics\")\n",
    "if os.path.exists(eval_dir):\n",
    "    shutil.rmtree(eval_dir) # Delete the old evaluation file folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1431728",
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_response_files = [f for f in os.listdir(output_dir) if f.endswith('.json')]\n",
    "print(f\"{len(existing_response_files)}/{img_total} of the images have been processed so far.\\n\")\n",
    "eval_cls_lite(results, cls_criteria, class_labels)\n",
    "results_path = os.path.join(output_dir, \"results.csv\")\n",
    "results.to_csv(results_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
